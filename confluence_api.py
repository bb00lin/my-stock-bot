import os
import requests
import json
import re
import sys
from datetime import datetime, timedelta, date
from requests.auth import HTTPBasicAuth
from urllib.parse import urlparse

# --- è¨­å®šå€ ---
RAW_URL = os.environ.get("CONF_URL")
USERNAME = os.environ.get("CONF_USER")
API_TOKEN = os.environ.get("CONF_PASS")

if not RAW_URL or not USERNAME or not API_TOKEN:
    print("éŒ¯èª¤ï¼šç¼ºå°‘ç’°å¢ƒè®Šæ•¸")
    sys.exit(1)

parsed = urlparse(RAW_URL)
BASE_URL = f"{parsed.scheme}://{parsed.netloc}"
API_ENDPOINT = f"{BASE_URL}/wiki/rest/api/content"

def find_latest_report():
    print("æ­£åœ¨æœå°‹æœ€æ–°é€±å ±...")
    cql = 'type=page AND title ~ "WeeklyReport*" ORDER BY created DESC'
    url = f"{API_ENDPOINT}/search"
    params = {'cql': cql, 'limit': 1, 'expand': 'body.storage,ancestors,space'}
    
    try:
        response = requests.get(url, auth=HTTPBasicAuth(USERNAME, API_TOKEN), params=params)
        response.raise_for_status()
        results = response.json().get('results', [])
        if not results:
            print("âš ï¸ æ‰¾ä¸åˆ°ä»»ä½•åŸºæº–é€±å ±ã€‚")
            sys.exit(1)
        latest = results[0]
        print(f"âœ… æ‰¾åˆ°åŸºæº–é€±å ±: {latest['title']} (ID: {latest['id']})")
        return latest
    except Exception as e:
        print(f"âŒ æœå°‹å¤±æ•—: {e}")
        sys.exit(1)

def calculate_next_date(latest_title):
    """
    è¨ˆç®—ä¸‹ä¸€æœŸçš„æª”åèˆ‡æ—¥æœŸå€é–“
    """
    match = re.search(r"(\d{8})", latest_title)
    # é è¨­ä½¿ç”¨æœ¬é€±ä½œç‚ºå‚™æ¡ˆ
    today = datetime.now().date()
    friday = today + timedelta(days=(4 - today.weekday()))
    
    if match:
        last_date_str = match.group(1)
        try:
            last_date_obj = datetime.strptime(last_date_str, "%Y%m%d").date()
            friday = last_date_obj + timedelta(days=7)
        except ValueError: pass
    
    # æ ¹æ“šæ–°çš„é€±äº” (æª”å)ï¼Œæ¨ç®—è©²é€±çš„é€±ä¸€èˆ‡é€±æ—¥
    # é€±å ±æª”åé€šå¸¸æ˜¯é€±äº”ï¼Œæ‰€ä»¥é€±ä¸€ = é€±äº” - 4å¤©
    target_monday = friday - timedelta(days=4)
    target_sunday = friday + timedelta(days=2)
    
    return {
        "filename": friday.strftime("%Y%m%d"),
        "monday": target_monday,
        "sunday": target_sunday
    }

def update_jql_dates_smart(content, new_monday_obj, new_sunday_obj):
    """
    v7.0 æ ¸å¿ƒä¿®æ­£ï¼šä¸ä¾è³´ç‰¹å®šèªæ³• (å¦‚ updated >=)ï¼Œè€Œæ˜¯ç›´æ¥é‡å°æ—¥æœŸå­—ä¸²é€²è¡Œæ›¿æ›ã€‚
    èƒ½å¤ è™•ç† "2026-1-19" (å–®ç¢¼) èˆ‡ "2026-01-19" (é›™ç¢¼) çš„å·®ç•°ã€‚
    """
    print(f"æ­£åœ¨åŸ·è¡Œæ™ºæ…§æ—¥æœŸæ›¿æ›...")
    
    # 1. æ‰¾å‡ºå…§å®¹ä¸­æ‰€æœ‰çœ‹èµ·ä¾†åƒæ—¥æœŸçš„å­—ä¸² (YYYY-M-D æˆ– YYYY-MM-DD)
    # Regex è§£é‡‹: 4ä½æ•¸å­— - 1åˆ°2ä½æ•¸å­— - 1åˆ°2ä½æ•¸å­—
    date_pattern = re.compile(r'(\d{4})-(\d{1,2})-(\d{1,2})')
    
    # 2. åˆ†æé€™äº›æ—¥æœŸï¼Œæ‰¾å‡ºå“ªäº›æ˜¯ã€ŒèˆŠé€±ä¸€ã€ï¼Œå“ªäº›æ˜¯ã€ŒèˆŠé€±æ—¥ã€
    # æˆ‘å€‘å‡è¨­èˆŠé€±å ±è£¡çš„æ—¥æœŸï¼Œå¤§éƒ¨åˆ†éƒ½è½åœ¨ã€Œä¸Šä¸€é€±ã€çš„å€é–“å…§
    # é‚è¼¯ï¼š
    #   èˆŠé€±ä¸€æ‡‰è©²æ˜¯: new_monday - 7 days
    #   èˆŠé€±æ—¥æ‡‰è©²æ˜¯: new_sunday - 7 days
    
    old_monday_target = new_monday_obj - timedelta(days=7)
    old_sunday_target = new_sunday_obj - timedelta(days=7)
    
    print(f"ç›®æ¨™ï¼šå°‡ {old_monday_target} é™„è¿‘çš„æ—¥æœŸæ›æˆ {new_monday_obj}")
    print(f"ç›®æ¨™ï¼šå°‡ {old_sunday_target} é™„è¿‘çš„æ—¥æœŸæ›æˆ {new_sunday_obj}")
    
    def replace_callback(match):
        full_str = match.group(0) # ä¾‹å¦‚ "2026-1-19" æˆ– "2026-01-19"
        
        try:
            # å˜—è©¦è§£æé€™å€‹æ—¥æœŸ
            found_date = datetime.strptime(full_str, "%Y-%m-%d" if "-" in full_str else "%Y%m%d").date()
            
            # åˆ¤æ–·é€™å€‹æ—¥æœŸæ˜¯ä¸æ˜¯ã€ŒèˆŠé€±ä¸€ã€ (å…è¨±å‰å¾Œ 1 å¤©çš„èª¤å·®ï¼Œä»¥é˜²è¬ä¸€)
            if abs((found_date - old_monday_target).days) <= 1:
                # æ›¿æ›æˆæ–°é€±ä¸€ (ä¿æŒåŸæœ¬æ ¼å¼å—ï¼Ÿä¸ï¼Œçµ±ä¸€æ”¹æˆæ¨™æº–æ ¼å¼ YYYY-MM-DD æœ€ä¿éšª)
                return new_monday_obj.strftime("%Y-%m-%d")
            
            # åˆ¤æ–·é€™å€‹æ—¥æœŸæ˜¯ä¸æ˜¯ã€ŒèˆŠé€±æ—¥ã€
            if abs((found_date - old_sunday_target).days) <= 1:
                return new_sunday_obj.strftime("%Y-%m-%d")
                
        except ValueError:
            pass
            
        return full_str # å¦‚æœä¸ç¬¦åˆæ¢ä»¶ï¼Œä¿æŒåŸæ¨£

    # 3. åŸ·è¡Œå…¨åŸŸæ›¿æ›
    new_content = date_pattern.sub(replace_callback, content)
    
    return new_content

def create_new_report(latest_page):
    # 1. è¨ˆç®—æ—¥æœŸ
    next_dates = calculate_next_date(latest_page['title'])
    new_title = f"WeeklyReport_{next_dates['filename']}"
    print(f"æº–å‚™å»ºç«‹: {new_title}")
    print(f"æ–°é€±æœŸ: {next_dates['monday']} ~ {next_dates['sunday']}")
    
    # 2. æª¢æŸ¥é‡è¤‡
    check_url = f"{API_ENDPOINT}/search"
    check_params = {'cql': f'title = "{new_title}"'}
    check_resp = requests.get(check_url, auth=HTTPBasicAuth(USERNAME, API_TOKEN), params=check_params)
    if check_resp.json().get('results'):
        print(f"âš ï¸ è·³éï¼šé é¢ '{new_title}' å·²ç¶“å­˜åœ¨ï¼")
        return

    # 3. è™•ç†å…§å®¹
    original_body = latest_page['body']['storage']['value']
    
    # ä½¿ç”¨ v7.0 çš„æ™ºæ…§æ›¿æ›å‡½æ•¸
    new_body = update_jql_dates_smart(
        original_body, 
        next_dates['monday'], 
        next_dates['sunday']
    )
    
    # 4. å»ºç«‹é é¢
    ancestors = []
    if latest_page.get('ancestors'):
        ancestors.append({'id': latest_page['ancestors'][-1]['id']})
    
    payload = {
        "title": new_title,
        "type": "page",
        "space": {"key": latest_page['space']['key']},
        "ancestors": ancestors,
        "body": {
            "storage": {
                "value": new_body,
                "representation": "storage"
            }
        }
    }
    
    try:
        response = requests.post(
            API_ENDPOINT, 
            auth=HTTPBasicAuth(USERNAME, API_TOKEN),
            headers={"Content-Type": "application/json"},
            data=json.dumps(payload)
        )
        response.raise_for_status()
        data = response.json()
        webui = data['_links']['webui']
        link = f"{BASE_URL}/wiki{webui}" if not webui.startswith('/wiki') else f"{BASE_URL}{webui}"
        
        print(f"ğŸ‰ æˆåŠŸå»ºç«‹ï¼é€£çµ: {link}")
        
    except requests.exceptions.HTTPError as e:
        print(f"âŒ å»ºç«‹å¤±æ•—: {e}")
        print(response.text)

def main():
    print(f"=== Confluence API è‡ªå‹•é€±å ± (v7.0 æ™ºæ…§æ—¥æœŸæ›¿æ›ç‰ˆ) ===")
    latest_page = find_latest_report()
    create_new_report(latest_page)

if __name__ == "__main__":
    main()
