import os
import requests
import json
import sys
from datetime import datetime
from dateutil.relativedelta import relativedelta
from requests.auth import HTTPBasicAuth
from bs4 import BeautifulSoup

# ==========================================
# 1. è¨­å®šå€
# ==========================================
RAW_URL = os.environ.get("CONF_URL")
USERNAME = os.environ.get("CONF_USER")
API_TOKEN = os.environ.get("CONF_PASS")

# ç›®æ¨™é é¢ ID (Timeline æ¸¬è©¦é )
TARGET_PAGE_ID = "76775427" 

if not RAW_URL or not USERNAME or not API_TOKEN:
    print("âŒ éŒ¯èª¤ï¼šç¼ºå°‘ç’°å¢ƒè®Šæ•¸ (CONF_URL, CONF_USER, CONF_PASS)")
    sys.exit(1)

parsed_url = RAW_URL.strip().rstrip('/')
# è™•ç†æœ‰äº› URL çµå°¾å¯èƒ½å¸¶æœ‰ /wiki çš„æƒ…æ³
if parsed_url.endswith('/wiki'):
    BASE_URL = parsed_url[:-5] # ç§»é™¤çµå°¾çš„ /wiki ä»¥ä¾¿çµ„è£ API è·¯å¾‘
else:
    BASE_URL = parsed_url

API_ENDPOINT = f"{BASE_URL}/wiki/rest/api/content"

def get_headers():
    return {"Content-Type": "application/json"}

# ==========================================
# 2. æ ¸å¿ƒåŠŸèƒ½
# ==========================================

def get_page_content(page_id):
    url = f"{API_ENDPOINT}/{page_id}"
    params = {'expand': 'body.storage,version,space'}
    try:
        r = requests.get(url, auth=HTTPBasicAuth(USERNAME, API_TOKEN), params=params)
        r.raise_for_status()
        return r.json()
    except Exception as e:
        print(f"âŒ è®€å–å¤±æ•—: {e}")
        return None

def add_one_month(date_str):
    formats = ["%Y-%m-%d", "%Y/%m/%d", "%Y-%m", "%Y/%m"]
    for fmt in formats:
        try:
            dt = datetime.strptime(date_str, fmt)
            new_dt = dt + relativedelta(months=1)
            if '-' in date_str: return new_dt.strftime("%Y-%m-%d")
            if '/' in date_str: return new_dt.strftime("%Y/%m/%d")
            return new_dt.strftime(fmt)
        except ValueError:
            continue
    return date_str

def modify_timeline_dates(html_content):
    print("ğŸ”§ æ­£åœ¨è§£æ Timeline (Roadmap) çµæ§‹...")
    try:
        import lxml
        soup = BeautifulSoup(html_content, 'xml')
    except ImportError:
        print("âŒ éŒ¯èª¤ï¼šè«‹å…ˆå®‰è£ lxml å¥—ä»¶")
        sys.exit(1)

    bars = soup.find_all('ac:structured-macro', attrs={"ac:name": "roadmap-bar"})
    print(f"   ğŸ” æ‰¾åˆ° {len(bars)} å€‹ Timeline Bar")

    modified_count = 0
    for bar in bars:
        title_param = bar.find('ac:parameter', attrs={"ac:name": "title"})
        title = title_param.get_text() if title_param else "æœªå‘½å"

        start_param = bar.find('ac:parameter', attrs={"ac:name": "startdate"})
        if start_param and start_param.string:
            old_start = start_param.string
            new_start = add_one_month(old_start)
            if old_start != new_start:
                start_param.string = new_start
                print(f"      ğŸ”„ [{title}] é–‹å§‹: {old_start} -> {new_start}")
                modified_count += 1

        end_param = bar.find('ac:parameter', attrs={"ac:name": "enddate"})
        if end_param and end_param.string:
            old_end = end_param.string
            new_end = add_one_month(old_end)
            if old_end != new_end:
                end_param.string = new_end
                print(f"      ğŸ”„ [{title}] çµæŸ: {old_end} -> {new_end}")
                modified_count += 1

    return str(soup), modified_count

def update_page(page_data, new_content):
    page_id = page_data['id']
    title = page_data['title']
    version = page_data['version']['number'] + 1
    
    payload = {
        "id": page_id,
        "type": "page",
        "title": title,
        "space": {"key": page_data['space']['key']},
        "body": {
            "storage": {
                "value": new_content,
                "representation": "storage"
            }
        },
        "version": {
            "number": version,
            "minorEdit": True
        }
    }

    url = f"{API_ENDPOINT}/{page_id}"
    try:
        r = requests.put(url, auth=HTTPBasicAuth(USERNAME, API_TOKEN), headers=get_headers(), data=json.dumps(payload))
        r.raise_for_status()
        print(f"âœ… é é¢æ›´æ–°æˆåŠŸï¼(ç‰ˆæœ¬ v{version})")
    except Exception as e:
        print(f"âŒ æ›´æ–°å¤±æ•—: {e}")
        print(r.text)

def main():
    print(f"=== Timeline å°ˆé …æ¸¬è©¦ (ç›®æ¨™ ID: {TARGET_PAGE_ID}) ===")
    page_data = get_page_content(TARGET_PAGE_ID)
    if not page_data: return

    print(f"ğŸ“„ è®€å–é é¢æˆåŠŸ: {page_data['title']}")
    original_body = page_data['body']['storage']['value']
    new_body, count = modify_timeline_dates(original_body)

    if count > 0:
        print(f"ğŸ“Š å…±ä¿®æ”¹äº† {count} å€‹æ™‚é–“é»ï¼Œæº–å‚™ä¸Šå‚³...")
        update_page(page_data, new_body)
    else:
        print("âš ï¸ æœªç™¼ç¾å¯ä¿®æ”¹çš„ Timeline æ—¥æœŸ")

if __name__ == "__main__":
    main()
