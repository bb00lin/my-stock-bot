import os
import requests
import json
import sys
from datetime import datetime
from dateutil.relativedelta import relativedelta
from requests.auth import HTTPBasicAuth
from bs4 import BeautifulSoup

# ==========================================
# 1. è¨­å®šå€
# ==========================================
# è«‹ç¢ºä¿ç’°å¢ƒè®Šæ•¸å·²è¨­å®šï¼Œæˆ–ç›´æ¥å¡«å…¥ (æ¸¬è©¦ç”¨)
RAW_URL = os.environ.get("CONF_URL")
USERNAME = os.environ.get("CONF_USER")
API_TOKEN = os.environ.get("CONF_PASS")

# æ‚¨æä¾›çš„ç›®æ¨™é é¢ ID (å¾ç¶²å€ .../pages/edit-v2/76775427 å¾—çŸ¥)
TARGET_PAGE_ID = "76775427" 

if not RAW_URL or not USERNAME or not API_TOKEN:
    print("âŒ éŒ¯èª¤ï¼šç¼ºå°‘ç’°å¢ƒè®Šæ•¸ (CONF_URL, CONF_USER, CONF_PASS)")
    sys.exit(1)

BASE_URL = RAW_URL.rstrip('/')
API_ENDPOINT = f"{BASE_URL}/rest/api/content"

def get_headers():
    return {"Content-Type": "application/json"}

# ==========================================
# 2. æ ¸å¿ƒåŠŸèƒ½
# ==========================================

def get_page_content(page_id):
    """è®€å–é é¢å…§å®¹"""
    url = f"{API_ENDPOINT}/{page_id}"
    params = {'expand': 'body.storage,version,space'}
    try:
        r = requests.get(url, auth=HTTPBasicAuth(USERNAME, API_TOKEN), params=params)
        r.raise_for_status()
        return r.json()
    except Exception as e:
        print(f"âŒ è®€å–å¤±æ•—: {e}")
        return None

def add_one_month(date_str):
    """æ—¥æœŸåŠ ä¸€å€‹æœˆï¼Œæ”¯æ´å¤šç¨®æ ¼å¼"""
    formats = ["%Y-%m-%d", "%Y/%m/%d", "%Y-%m", "%Y/%m"]
    for fmt in formats:
        try:
            dt = datetime.strptime(date_str, fmt)
            new_dt = dt + relativedelta(months=1)
            # ä¿æŒåŸæ ¼å¼å›å‚³
            if '-' in date_str: return new_dt.strftime("%Y-%m-%d")
            if '/' in date_str: return new_dt.strftime("%Y/%m/%d")
            return new_dt.strftime(fmt)
        except ValueError:
            continue
    return date_str

def modify_timeline_dates(html_content):
    """
    è§£æ XMLï¼Œå°ˆé–€å°‹æ‰¾ roadmap-bar ä¸¦ä¿®æ”¹æ—¥æœŸ
    """
    print("ğŸ”§ æ­£åœ¨è§£æ Timeline (Roadmap) çµæ§‹...")
    
    try:
        import lxml
        soup = BeautifulSoup(html_content, 'xml') # å¿…é ˆä½¿ç”¨ xml æ¨¡å¼
    except ImportError:
        print("âŒ éŒ¯èª¤ï¼šè«‹å…ˆå®‰è£ lxml å¥—ä»¶ (pip install lxml)")
        sys.exit(1)

    # æœå°‹æ‰€æœ‰çš„ roadmap-bar å·¨é›†
    bars = soup.find_all('ac:structured-macro', attrs={"ac:name": "roadmap-bar"})
    print(f"   ğŸ” æ‰¾åˆ° {len(bars)} å€‹ Timeline Bar")

    modified_count = 0

    for bar in bars:
        # å–å¾—æ¨™é¡Œ (åƒ…ä¾›é¡¯ç¤ºç”¨)
        title_param = bar.find('ac:parameter', attrs={"ac:name": "title"})
        title = title_param.get_text() if title_param else "æœªå‘½å"

        # ä¿®æ”¹ Start Date
        start_param = bar.find('ac:parameter', attrs={"ac:name": "startdate"})
        if start_param and start_param.string:
            old_start = start_param.string
            new_start = add_one_month(old_start)
            if old_start != new_start:
                start_param.string = new_start
                print(f"      ğŸ”„ [{title}] é–‹å§‹æ™‚é–“: {old_start} -> {new_start}")
                modified_count += 1

        # ä¿®æ”¹ End Date
        end_param = bar.find('ac:parameter', attrs={"ac:name": "enddate"})
        if end_param and end_param.string:
            old_end = end_param.string
            new_end = add_one_month(old_end)
            if old_end != new_end:
                end_param.string = new_end
                print(f"      ğŸ”„ [{title}] çµæŸæ™‚é–“: {old_end} -> {new_end}")
                modified_count += 1

    return str(soup), modified_count

def update_page(page_data, new_content):
    """æ›´æ–°é é¢ (è¨­å®šä¸é€šçŸ¥)"""
    page_id = page_data['id']
    title = page_data['title']
    version = page_data['version']['number'] + 1
    
    payload = {
        "id": page_id,
        "type": "page",
        "title": title,
        "space": {"key": page_data['space']['key']},
        "body": {
            "storage": {
                "value": new_content,
                "representation": "storage"
            }
        },
        "version": {
            "number": version,
            "minorEdit": True # ä¸é€šçŸ¥è¿½è¹¤è€…
        }
    }

    url = f"{API_ENDPOINT}/{page_id}"
    try:
        r = requests.put(url, auth=HTTPBasicAuth(USERNAME, API_TOKEN), headers=get_headers(), data=json.dumps(payload))
        r.raise_for_status()
        print(f"âœ… é é¢æ›´æ–°æˆåŠŸï¼(ç‰ˆæœ¬ v{version})")
        print(f"ğŸ”— é€£çµ: {BASE_URL}/spaces/{page_data['space']['key']}/pages/{page_id}")
    except Exception as e:
        print(f"âŒ æ›´æ–°å¤±æ•—: {e}")
        print(r.text)

def main():
    print(f"=== Timeline å°ˆé …æ¸¬è©¦ (ç›®æ¨™ ID: {TARGET_PAGE_ID}) ===")
    
    # 1. å–å¾—é é¢
    page_data = get_page_content(TARGET_PAGE_ID)
    if not page_data: return

    print(f"ğŸ“„ è®€å–é é¢æˆåŠŸ: {page_data['title']}")

    # 2. ä¿®æ”¹ Timeline
    original_body = page_data['body']['storage']['value']
    new_body, count = modify_timeline_dates(original_body)

    if count > 0:
        print(f"ğŸ“Š å…±ä¿®æ”¹äº† {count} å€‹æ™‚é–“é»ï¼Œæº–å‚™ä¸Šå‚³...")
        # 3. ä¸Šå‚³æ›´æ–°
        update_page(page_data, new_body)
    else:
        print("âš ï¸ æœªç™¼ç¾ä»»ä½•å¯ä¿®æ”¹çš„ Timeline æ—¥æœŸï¼Œè«‹ç¢ºèªé é¢å…§å®¹ã€‚")

if __name__ == "__main__":
    main()
